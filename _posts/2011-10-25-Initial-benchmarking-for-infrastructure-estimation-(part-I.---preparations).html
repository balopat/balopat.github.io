---           
layout: post
title: Initial benchmarking for infrastructure estimation (part I. - preparations)
date: 2011-10-25 20:12:00 UTC
updated: 2013-12-14 19:44:55 UTC
comments: false
categories: Web/Tech Weblogs
---
 
<p>In huge enterprises getting hold of the physical/virtual machines and servers is not an easy task. It takes ages to approve them and another decade to actually get them with all the software installed and configured.<br /><br /> If you find yourself in the same shoes, however agile your project is intended to be, you have to carefully excersise benchmark tests <strong>upfront</strong> to justify your requests for two reasons:<br /><br /></p><br /><ol><br /><li><em>The impact of undersizing </em>the machines is huge, you definitely do not want to run into a situation in production where your infrastructure cannot deal with the load, when your physical scaling suffers from monthly latency.</li><br /><li><em>Oversizing </em>the infrastructure will certainly solve the first issue but raises a risk in the approval process. (image the grasping managers hearing about the licensing costs)</li><br /></ol><br /><p>&#0160;<br /></p><br /><br/><p><br /><strong>Agile concerns </strong></p><br /><p>At this point the fact that <em>you do not know</em> how your system will work might cause you some headache. It did for me, that&#39;s why I am sharing these methods, it might save some time for someone.</p><br /><p>Also if you have any comments, please share. As I am writing this I am constantly thinking how this could be taken in a more agile way, but organizational constraints do not really help in it.</p><br /><p>I think initial infrastructure estimation is a similar one-off activity to the initial budgeting - in fact it is an organic part of initial budgeting.</p><br /><p>The result of the initial effort estimation is a plan which is throw-away but the <strong>value is in the planning itself</strong>, the fact that you think the whole backlog through and put an initial version together.</p><br /><p>The result of the inital infrastructure estimation will be similarly a &quot;within boundaries&quot; plan good to start with but the byproducts will be very valuable:</p><br /><ul><br /><li><strong>proof of concept codesnippets </strong>will reveal some initial problems already and help you improve the first version of the actual code</li><br /><li><strong>automated benchmarking </strong>should be written in a way that you can later wire it up to your CI environment so that it can be trended out later</li><br /></ul><br /><p><strong>Case study</strong></p><br /><p><em>Disclaimer</em>: these questions and examples are just the result of our thought process in my daytime job. Your software might be really different, do not use this as a complete template, my intention is to inspire and give your thoughts a skeleton. You might do more or less to get your concept approved :)</p><br /><p>So let&#39;s see our case study. We are writing a high throughput system, with millions of messages per day with a distributed cache solution to make it damn fast. <br /><br />We are after the inital planning estimation, the initial product backlog is ready, so we have a relatively good understanding about the functional requirements.<br /><br />There are five main activities we have to tackle:<br /><br /></p><br /><table><br /><tbody><br /><tr><br /><td><br /><ul><br /><li><span style="font-size: 8pt;">collect business requirements and facts</span></li><br /><li><span style="font-size: 8pt;">decide about the failover/availabilty mechanism</span></li><br /><li><span style="font-size: 8pt;">determine preliminary design decision-points</span></li><br /><li><span style="font-size: 8pt;">write and run benchmark tests on the most likely decision branches </span></li><br /><li><span style="font-size: 8pt;">evaluate the results in terms of requirements</span></li><br /></ul><br /></td><br /><td><a href="http://balopat.typepad.com/.a/6a015392885777970b015392956c04970b-pi" style="display: inline;"><img alt="Infra blog post figures" border="0" class="asset  asset-image at-xid-6a015392885777970b015392956c04970b" height="200px" src="http://balopat.typepad.com/.a/6a015392885777970b015392956c04970b-800wi" title="Infra blog post figures" /></a><br /></td><br /></tr><br /></tbody><br /></table><br /><p>In the first part of this article the first three will be covered.&#0160;</p><br /><p><strong>Business requirements and facts</strong><br /><br />Collect as much data as you can! Facts are already out there, think about how you can get them!<br />Business requirements are probably only just as hard to collect as usually in every project. Here are some sample questions we asked and example answers behind them:</p><br /><ol><br /><li>What is the max latency your system should handle? (e.g. 5 minutes)</li><br /><li>What is the estimated throughput daily, on average and during peak times? (e.g. daily 2 million on average, peak times will be four weeks in a year, each day around 6 million messages)</li><br /><li>What is the distribution in an hourly basis for this x event/day? i.e. What  are the peak hours and how much data would go through them? (e.g. the peak hour is&#0160; around 17:00-18:00 which will take the 20% of the daily rate) </li><br /><li>you can get from the peak hour the event number per second during peak time (e.g.: 6 million * 20% = 1.2 million/hour = 333 message/sec)</li><br /><li>is there a similar system already around you? </li><br /><li>is there a datawarehouse or other system which might contain some information about the daily information flow? Use it! (e.g. I used it to determine the size of the messages)</li><br /><li>is there an external system with which your system will share upstream systems either indirectly or directly? Use stats out of it if you can! (i used our confirmation system to get the hourly distribution of the number of messages in a day, because it uses the same frontends)</li><br /><li>what is the archiving strategy for the processed data?</li><br /></ol><br /><p><strong>Failover mechanisms and high availability&#0160;&#0160;&#0160;&#0160;<br /></strong></p><br /><ul><br /></ul><br /><p>You have to reach an agreement with your stakeholders about the <a href="http://searchstorage.techtarget.com/feature/What-is-the-difference-between-RPO-and-RTO-from-a-backup-perspective" target="_blank" title="RTO and RPO">RTO and RPO</a> for  different scenarios (host failover, db failover, datacentre failover).&#0160; There is a trade-off here between the price of the solution and the time of failing over/size of dataloss. The more unlikely the scenario the harder to get around it. To provide a quick and dataloss-free failover in the case of a whole datacentre can be very expensive, because you have to find a way to keep your BCP site warm constantly.</p><br /><p>Decide about the following questions:</p><br /><ol><br /><li>Do you need a highly available system? Then you will need some kind of hotstandby mechanism probably which can take over instantly the work of the failed hosts/servers</li><br /><li>Do you need Oracle RAC level service or you can solve database high-availability on an application level (e.g. using failover mechanism in the JDBC connection management)</li><br /><li>Do you need to SRDF for replication of disk data or you can solve keeping the BCP site warm on an application level?</li><br /><li>If you can allow a cold startup on the BCP site then what is the maximum time (derived from the RTO) the system should start up? </li><br /></ol><br /><p><strong>Critical paths</strong></p><br /><p>In a high throughput or low latency system always think about all the components whether they are on the critical path or not. A backup store might not be on the critical pathway for example during normal operation but on failover scenarios it might well be and thus be a potential bottleneck against your promised RTO!</p><br /><p><strong>Design decision-points</strong><br /><br />This is the toughest part. Try not to overthink it, and be pragmatic.</p><br /><p>Draw down the <strong>process</strong> which your software will support and identify the <strong>components</strong>. Each of these components might be a bottleneck, so you should find <strong>a way to scale them up</strong>. Think about the usual and the failover <strong>scenarios</strong> in terms of each component and the possible solutions.</p><br /><p>Key decision design points will have a few possible solutions. For each of these solutions you can draw a tree like this.</p><br /><ol> <a href="http://balopat.typepad.com/.a/6a015392885777970b015392956b7f970b-pi" style="display: inline;"> </a> <a href="http://balopat.typepad.com/.a/6a015392885777970b0162fbeabfc6970d-popup" onclick="window.open( this.href, &#39;_blank&#39;, &#39;width=640,height=480,scrollbars=no,resizable=no,toolbar=no,directories=no,location=no,menubar=no,status=no,left=0,top=0&#39; ); return false" style="float: left;"><img alt="Infra blog post figures(1)" class="asset  asset-image at-xid-6a015392885777970b0162fbeabfc6970d" src="http://balopat.typepad.com/.a/6a015392885777970b0162fbeabfc6970d-400wi" style="width: 400px; margin: 0px 5px 5px 0px;" title="Infra blog post figures(1)" /></a></ol><br /><p>&#0160;</p><br /><p>&#0160;</p><br /><p>&#0160;</p><br /><p>&#0160;</p><br /><p>&#0160;</p><br /><p>&#0160;</p><br /><p>&#0160;</p><br /><p>&#0160;</p><br /><p>&#0160;</p><br /><p>The meaningful routes will give you your testcases.</p><br /><p>Some example design decision-points and some possible scenarios (if makes sense!):</p><br /><table border="1"><br /><tbody><br /><tr><br /><td><br /><p>&#0160;</p><br /><p><strong>design decision point</strong></p><br /><p>&#0160;</p><br /></td><br /><td><br /><p>&#0160;</p><br /><p><strong>scenarios/thoughts</strong></p><br /><p>&#0160;</p><br /></td><br /></tr><br /><tr><br /><td>How will you handle repopulation of your cache? <br /></td><br /><td><br /><p>&#0160;Getting all the active working set might be tricky. we have versioning logic, and we want only the latest ones to be included in the working set. Possible scenarios:</p><br /><p>1. Using a trigger in database to update an is_latest flag</p><br /><p>2. Using an analytic query with some indexes</p><br /><p>3. Using an asynchronous maintainer job to archive the old versions in a non-blocking way</p><br /></td><br /></tr><br /><tr><br /><td>Indexing strategy, table structures<br /></td><br /><td><br /><p>1. if you use is_latest you should use index on the is_latest</p><br /><p>2. if you use analytic query you might want to use some indexes to make it performant</p><br /><p>3. If the table is ensured to contain only your working set, you might not use indexes at all - this will improve the insert performance of course</p><br /></td><br /></tr><br /><tr><br /><td>How old your cached objects will be?</td><br /><td>No scenarios are needed for this, or too complicated to solve. I  just  say 0.15% of my live objects will be in memory. This will be good   enough for the estimation.</td><br /></tr><br /><tr><br /><td><br /><p>Do you need ordering in your distributed system? I.e. is the output a function of the order of the incoming messages?</p><br /></td><br /><td><br /><p>Decide of one of these and write one of them in the PoC</p><br /><p>1. No</p><br /><p>2. Yes, there will be a waiting period fo</p><br /><p>3. Yes, lots of messages might queue up</p><br /></td><br /></tr><br /><tr><br /><td>Do you need to care about concurrently arriving duplicates? <br /></td><br /><td><br /><p>1. No</p><br /><p>2. Yes, then how will you solve the communication between the manipulating threads? Will you have a cache with business keys?</p><br /></td><br /></tr><br /><tr><br /><td>Do you have concurrent writes on the same resources? <br /></td><br /><td><br /><p>1. No&#0160;</p><br /><p>2.Yes, then how will you solve the communication between the manipulating threads? How will you lock the data?</p><br /></td><br /></tr><br /></tbody><br /></table><br /><p>&#0160;</p><br /><p>What&#39;s next?</p><br /><p>In the upcoming weeks I&#39;ll put together the second part of this post containing:</p><br /><ul><br /><li>Some tricks and tips for writing automated benchmark tests with Oracle AWR and JMeter/Hudson integration.</li><br /><li>Evaluation of the results&#0160;</li><br /></ul><br /><p>&#0160;</p><br />